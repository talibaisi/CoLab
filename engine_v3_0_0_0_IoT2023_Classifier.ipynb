{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlYrUb/9KlVS1IDRdTc0ap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talibaisi/CoLab/blob/master/engine_v3_0_0_0_IoT2023_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_h4q9IKfGpr"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import csv\n",
        "import time\n",
        "import joblib\n",
        "\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import logging\n",
        "\n",
        "\n",
        "#GPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "import resource\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
        "from sklearn.base import clone\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.nn import BCELoss, Sigmoid\n",
        "from torch.optim import Adam\n",
        "\n",
        "import sqlite3\n",
        "import numpy as np\n",
        "import logging,sys\n",
        "import pandas as pd\n",
        "from joblib import dump, load\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from sklearn.ensemble import StackingClassifier,BaggingClassifier, GradientBoostingClassifier\n",
        "#Machine Learning packages import\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import datetime\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import torch.nn.functional as F\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "#Global parameters\n",
        "#==================================================\n",
        "CIC_IoT_table_name = 'CIC-IoT-2023'\n",
        "\n",
        "# Define batch size\n",
        "CIC_IoT_Reading_Batch_Size = 300000\n",
        "DATAFAME_TO_SQLITE_BATCH_Size = 1000\n",
        "K_NO_OF_FEATURES_TO_SELECT = 20 #10  # Number of features to select\n",
        "isRunningOnLinux = False\n",
        "IDSLOG_FILE_MODE = 'a' # put 'w' if you want to start new fresh IDSLog.log rather than append to existing one\n",
        "n_Total_read_rows_from_CIC_IOT = None # put 'None' incase to read all records from CIC IoT csv (linux run)\n",
        "RESAMPLING_RATIO = 100\n",
        "RESAMPLE_ALGORITHM = 'SMOTE' #'ADASYN' #USE 'NONE' in case no sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#==================================================\n",
        "def calculate_g_mean(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    g_mean = np.sqrt(sensitivity * specificity)\n",
        "    return g_mean\n",
        "\n",
        "#Function to calculate and log skewness and kurtosis\n",
        "def log_skewness_kurtosis(data, feature_names):\n",
        "    logging.info(\"\")\n",
        "    logging.info(\"***********************************************************************\")\n",
        "    logging.info(\"log_skewness_kurtosis starts\")\n",
        "    logging.info(\"\")\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"***********************************************************************\")\n",
        "    print(\"log_skewness_kurtosis starts\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "    skewness = skew(data, axis=0)\n",
        "    kurt = kurtosis(data, axis=0)\n",
        "    for i, feature in enumerate(feature_names):\n",
        "        logging.info(f\"Feature: {feature} - Skewness: {skewness[i]}, Kurtosis: {kurt[i]}\")\n",
        "        print(f\"Feature: {feature} - Skewness: {skewness[i]}, Kurtosis: {kurt[i]}\")\n",
        "\n",
        "    logging.info(\"log_skewness_kurtosis ends\")\n",
        "    logging.info(\"***********************************************************************\")\n",
        "\n",
        "    print(\"log_skewness_kurtosis ends\")\n",
        "    print(\"***********************************************************************\")\n",
        "\n",
        "def ResampleDataFrame(df_all, classCol=\"Label\",commentOnDataframe=\"\"):\n",
        "        # Assuming 'label' is the column indicating benign (0) or attack (1)\n",
        "        # Split the data into features (X) and labels (y)\n",
        "        X = df_all.drop(classCol, axis=1)\n",
        "        y = df_all[classCol]\n",
        "\n",
        "        # Resample the imbalanced dataset using SMOTE or ADASYN\n",
        "        # Choose one of the following resampling techniques\n",
        "        # oversampler = SMOTE(sampling_strategy=0.5)  # SMOTE\n",
        "        logging.info('')\n",
        "        logging.info('****************************************************************')\n",
        "        logging.info('RESAMPLE ('+commentOnDataframe+') using '+RESAMPLE_ALGORITHM+' algorithm with ratio '+str(RESAMPLING_RATIO))\n",
        "        logging.info('****************************************************************')\n",
        "        logging.info('')\n",
        "\n",
        "        logging.info('y.unique() = '+str(y.unique()))\n",
        "        logging.info('y.value_counts() = '+str(y.value_counts()))\n",
        "        logging.info('')\n",
        "\n",
        "\n",
        "        print('')\n",
        "        print('****************************************************************')\n",
        "        print('RESAMPLE ('+commentOnDataframe+') using '+RESAMPLE_ALGORITHM+' algorithm with ratio '+str(RESAMPLING_RATIO))\n",
        "        print('****************************************************************')\n",
        "        print('')\n",
        "\n",
        "        print('y.unique() = '+str(y.unique()))\n",
        "        print('y.value_counts() = '+str(y.value_counts()))\n",
        "        print('')\n",
        "\n",
        "        if RESAMPLE_ALGORITHM == 'SMOTE':\n",
        "            oversampler = SMOTE(sampling_strategy=RESAMPLING_RATIO)  # SMOTE\n",
        "        else:\n",
        "            oversampler = ADASYN(sampling_strategy=RESAMPLING_RATIO)  # ADASYN\n",
        "\n",
        "\n",
        "        X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "        # Create a DataFrame from the resampled data\n",
        "        df_all = pd.DataFrame(data=X_resampled, columns=X.columns)\n",
        "        df_all[classCol] = y_resampled\n",
        "        return df_all\n",
        "\n",
        "\n",
        "# Define a function to split a floating-point value and return both parts\n",
        "def split_float(value):\n",
        "    try:\n",
        "        float_value = float(value)\n",
        "        before_dot = int(float_value)\n",
        "        after_dot = float_value - before_dot\n",
        "        return before_dot, after_dot\n",
        "    except ValueError:\n",
        "        return None, None\n",
        "\n",
        "#             My Methods Library\n",
        "def loggingpreparations(logname='IDSLog.log'):\n",
        "    #warnings.filterwarnings(\"ignore\")\n",
        "    logging.basicConfig(filename=logname,\n",
        "                    filemode=IDSLOG_FILE_MODE,\n",
        "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
        "                    datefmt='%d-%b-%y %H:%M:%S',\n",
        "                    level=logging.DEBUG)\n",
        "\n",
        "    logging.info(\"Running IDS Engine - Classifier Model\")\n",
        "    print(\"Running IDS Engine - Classifier Model\")\n",
        "\n",
        "\n",
        "def loggingpreparations_OnlyForBestModelTestingPhase(logname='IDSLog_ModelTestingPhase.log'):\n",
        "    #warnings.filterwarnings(\"ignore\")\n",
        "    logging.basicConfig(filename=logname,\n",
        "                    filemode='w',\n",
        "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
        "                    datefmt='%d-%b-%y %H:%M:%S',\n",
        "                    level=logging.DEBUG)\n",
        "\n",
        "    logging.info(\"Running IDS Engine - Model Testing Phase - Best DeepNN Classifier Model\")\n",
        "    print(\"Running IDS Engine - Model Testing Phase - Best DeepNN Classifier Model\")\n",
        "\n",
        "#Recursive To Vigesemal\n",
        "def tovigisemal(decimalstring):\n",
        "    dec = int(decimalstring)\n",
        "    x = (dec % 20)\n",
        "    digits = \"0123456789ABCDEFGHIJ\"\n",
        "    rest = dec / 20\n",
        "    if (rest == 0):\n",
        "        return digits[x]\n",
        "    return tovigisemal(rest) + digits[x]\n",
        "\n",
        "def sendJobFinishAlertMail(sFrom=\"ta0002@gmail.com\",sTo=\"ta0002@gmail.com\",sSubject=\"Job Finished\",sMessage=\"Your job is finished!\"):\n",
        "    # Email configuration\n",
        "    sender_email = sFrom\n",
        "    receiver_email = sTo\n",
        "    password = \"ywdorcecnqwqmsiz\"\n",
        "\n",
        "    # Create a MIMEText object\n",
        "    message = MIMEText(sMessage)\n",
        "\n",
        "    # Set the email subject\n",
        "    message[\"Subject\"] = sSubject\n",
        "\n",
        "    # Connect to the SMTP server\n",
        "    smtp_server = \"smtp.gmail.com\"\n",
        "    smtp_port = 587\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, password)\n",
        "\n",
        "        # Send the email\n",
        "        server.sendmail(sender_email, receiver_email, message.as_string())\n",
        "\n",
        "        # Close the server connection\n",
        "        server.quit()\n",
        "        print(\"Email sent successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Email could not be sent. Error: {str(e)}\")\n",
        "\n",
        "    return\n",
        "\n",
        "def create_folder_if_not_exists(folder_path):\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "      # Create the folder if it doesn't exist\n",
        "      os.makedirs(folder_path)\n",
        "      print(f\"Folder '{folder_path}' created.\")\n",
        "      print('*******************************************************')\n",
        "      print('')\n",
        "      print(f\"Folder '{folder_path}' created.\")\n",
        "      print('')\n",
        "  else:\n",
        "      print(f\"Folder '{folder_path}' already exists.\")\n",
        "      print('**************')\n",
        "      print('')\n",
        "      print(f\"Folder '{folder_path}' already exists.\")\n",
        "\n",
        "  print('*******************************************************')\n"
      ],
      "metadata": {
        "id": "dLKMViMVg9Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sMsg = 'This ML (CIC_IoT2023, K_NO_OF_FEATURES_TO_SELECT = '+str(K_NO_OF_FEATURES_TO_SELECT)+' ,Re-Sampling(Upsampling-SMOTE-Yeo-Johnson-transformation, RATIOs 0.25), also test Unseen 20% data with columns original order'\n",
        "# Example usage:\n",
        "print(sMsg)\n",
        "logging.info('************************************************************')\n",
        "logging.info('')\n",
        "logging.info('************************************************************')\n",
        "logging.info(sMsg)\n",
        "logging.info('************************************************************')\n",
        "\n",
        "folder_path = './saved_DNN_models'\n",
        "create_folder_if_not_exists(folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T0n9WpMi7Yd",
        "outputId": "dfa4bd8a-97a1-4b79-f2f4-2d4accea4167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This ML (CIC_IoT2023, K_NO_OF_FEATURES_TO_SELECT = 20 ,Re-Sampling(Upsampling-SMOTE-Yeo-Johnson-transformation, RATIOs 0.25), also test Unseen 20% data with columns original order\n",
            "Folder './saved_DNN_models' created.\n",
            "*******************************************************\n",
            "\n",
            "Folder './saved_DNN_models' created.\n",
            "\n",
            "*******************************************************\n"
          ]
        }
      ]
    }
  ]
}