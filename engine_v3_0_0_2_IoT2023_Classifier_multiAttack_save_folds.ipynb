{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28","mount_file_id":"13L0eOas5ULFXawFmQ329psG5RR2BGpyD","authorship_tag":"ABX9TyM1Lgo/0gU/RnQaeCvp6pau","include_colab_link":true},"accelerator":"TPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":12003002,"sourceType":"datasetVersion","datasetId":7550654},{"sourceId":12003791,"sourceType":"datasetVersion","datasetId":7551251}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/talibaisi/CoLab/blob/master/engine_v3_0_0_1_IoT2023_Classifier_multiAttack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"restore_checkpoints_from_dataset()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install scikeras catboost","metadata":{"id":"l6axIDU6o400","outputId":"9392815e-e22e-4bb2-b250-8092d01740e3","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:30.649547Z","iopub.execute_input":"2025-05-30T07:19:30.650585Z","iopub.status.idle":"2025-05-30T07:19:34.701807Z","shell.execute_reply.started":"2025-05-30T07:19:30.650542Z","shell.execute_reply":"2025-05-30T07:19:34.700602Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikeras in /usr/local/lib/python3.11/dist-packages (0.13.0)\nRequirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\nRequirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.7.2)\nRequirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\nRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.2)\nRequirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.13.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.14.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.16.0->catboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.16.0->catboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.16.0->catboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.16.0->catboost) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.16.0->catboost) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.16.0->catboost) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.0.9)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.16.0->catboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.16.0->catboost) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.16.0->catboost) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.16.0->catboost) (2024.2.0)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.16.0->catboost) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# prompt: mount google drive\n\n#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"id":"D5ALZZ_PvFhw","outputId":"c5705f29-72a8-4b74-e8d5-c36fe992a468","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:34.703641Z","iopub.execute_input":"2025-05-30T07:19:34.703945Z","iopub.status.idle":"2025-05-30T07:19:34.709223Z","shell.execute_reply.started":"2025-05-30T07:19:34.703916Z","shell.execute_reply":"2025-05-30T07:19:34.708140Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import shap\n# ✅ Disable HuggingFace transformer model detection in SHAP\nshap.utils.transformers.is_transformers_lm = lambda x: False","metadata":{"id":"ZxvdrYlkn84J","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:34.710176Z","iopub.execute_input":"2025-05-30T07:19:34.710481Z","iopub.status.idle":"2025-05-30T07:19:38.331874Z","shell.execute_reply.started":"2025-05-30T07:19:34.710456Z","shell.execute_reply":"2025-05-30T07:19:38.330995Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Assistantxxxx\n# Assistant\n# First, install the missing package\n#!pip install tensorflow==2.10.0 keras==2.10.0 scikeras --upgrade\n#!pip install catboost\n\n# Then your imports can work correctly\nfrom sklearn.linear_model import SGDClassifier  # Corrected import - SGDClassifier is in linear_model, not model_selection\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import scale\nimport os\nimport pandas as pd\nimport time\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\nimport joblib\nfrom joblib import dump, load\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom scipy.stats import skew, kurtosis\nfrom sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer\nfrom sklearn.ensemble import StackingClassifier,BaggingClassifier, GradientBoostingClassifier\nfrom sklearn.base import clone\n\nfrom imblearn.over_sampling import SMOTE, ADASYN\n\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# Use the updated import for KerasClassifier\nfrom scikeras.wrappers import KerasClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import Pipeline\n\nimport tensorflow as tf\nfrom sklearn.model_selection import GridSearchCV\n\nimport datetime\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.ensemble import IsolationForest,StackingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier  # This will work after installation\nfrom sklearn.metrics import matthews_corrcoef\nimport torch.nn.functional as F\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_selection import SelectFromModel\n\n\n#General hyper parameters\nK_FOLD_SPLITS=5\nEPOCHS = 5 #100\nRESAMPLE_ALGORITHM = 'SMOTE' #'ADASYN' #USE 'NONE' in case no sampling\nRESAMPLING_RATIO = 1.0\nLIME_FORCE_PLOT_SAMPLE_SLICE = 100\n\nbest_results = {\n'Naive Bayes': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Logistic Regression': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Decision Tree': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'K-Nearest Neighbor': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Support Vector Machine': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Random Forest': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'XGBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'AdaBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'CatBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Bagging': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Gradient Boosting': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'CNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'RNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'LSTM Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'GRU Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n#'GNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Stacking(Logistic Regression)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Stacking(Decision Tree)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None}\n}\n#################### multi label (attack_type)\nbest_results_attack_types= {\n'Naive Bayes': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Logistic Regression': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Decision Tree': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'K-Nearest Neighbor': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Support Vector Machine': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Random Forest': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'XGBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'AdaBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'CatBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Bagging': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Gradient Boosting': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'CNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'RNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'LSTM Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'GRU Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n#'GNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Stacking(Logistic Regression)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n'Stacking(Decision Tree)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None}\n}\n# Rest of your code remains the same","metadata":{"id":"gghv_9nmome1","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:38.334738Z","iopub.execute_input":"2025-05-30T07:19:38.335392Z","iopub.status.idle":"2025-05-30T07:19:38.375316Z","shell.execute_reply.started":"2025-05-30T07:19:38.335366Z","shell.execute_reply":"2025-05-30T07:19:38.374082Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#==================================================\ndef is_stacking_tree_model(model_name, estimator):\n    if 'Stacking' in model_name and isinstance(estimator, StackingClassifier):\n        if isinstance(estimator.final_estimator_, (DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier)):\n            return True\n    return False\n\ndef is_stacking_non_tree_model(model_name, estimator):\n    if 'Stacking' in model_name and isinstance(estimator, StackingClassifier):\n        if isinstance(estimator.final_estimator_, (LogisticRegression, SVC, KNeighborsClassifier)):\n            return True\n    return False\n\ndef logExecTime(strMethodName, start_time, end_time):\n    # Calculate the execution time in seconds\n    execution_time_seconds = end_time - start_time\n\n    # Convert the execution time to minutes\n    execution_time_minutes = execution_time_seconds / 60\n\n    # Print the execution time in minutes\n    print(str(strMethodName) + \" (Execution time) : {:.2f} minutes\".format(execution_time_minutes))\n\n    print('')\n    print('-------------------')\n    print(str(strMethodName) + \" (Execution time) : {:.2f} minutes\".format(execution_time_minutes))\n    print('-------------------')\n    print('')\ndef calculate_g_mean(y_true, y_pred):\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    sensitivity = tp / (tp + fn)\n    specificity = tn / (tn + fp)\n    g_mean = np.sqrt(sensitivity * specificity)\n    return g_mean\n\n#Function to calculate and log skewness and kurtosis\ndef log_skewness_kurtosis(data, feature_names):\n\n    print(\"\")\n    print(\"***********************************************************************\")\n    print(\"log_skewness_kurtosis starts\")\n    print(\"\")\n\n\n    skewness = skew(data, axis=0)\n    kurt = kurtosis(data, axis=0)\n    for i, feature in enumerate(feature_names):\n        print(f\"Feature: {feature} - Skewness: {skewness[i]}, Kurtosis: {kurt[i]}\")\n\n    print(\"log_skewness_kurtosis ends\")\n    print(\"***********************************************************************\")\n\n# Define a function to split a floating-point value and return both parts\ndef split_float(value):\n    try:\n        float_value = float(value)\n        before_dot = int(float_value)\n        after_dot = float_value - before_dot\n        return before_dot, after_dot\n    except ValueError:\n        return None, None\n\n\n#Recursive To Vigesemal\ndef tovigisemal(decimalstring):\n    dec = int(decimalstring)\n    x = (dec % 20)\n    digits = \"0123456789ABCDEFGHIJ\"\n    rest = dec / 20\n    if (rest == 0):\n        return digits[x]\n    return tovigisemal(rest) + digits[x]\n\ndef sendJobFinishAlertMail(sFrom=\"ta0002@gmail.com\",sTo=\"ta0002@gmail.com\",sSubject=\"Job Finished\",sMessage=\"Your job is finished!\"):\n    # Email configuration\n    sender_email = sFrom\n    receiver_email = sTo\n    password = \"ywdorcecnqwqmsiz\"\n\n    # Create a MIMEText object\n    message = MIMEText(sMessage)\n\n    # Set the email subject\n    message[\"Subject\"] = sSubject\n\n    # Connect to the SMTP server\n    smtp_server = \"smtp.gmail.com\"\n    smtp_port = 587\n\n    try:\n        server = smtplib.SMTP(smtp_server, smtp_port)\n        server.starttls()\n        server.login(sender_email, password)\n\n        # Send the email\n        server.sendmail(sender_email, receiver_email, message.as_string())\n\n        # Close the server connection\n        server.quit()\n        print(\"Email sent successfully!\")\n\n    except Exception as e:\n        print(f\"Email could not be sent. Error: {str(e)}\")\n\n    return\n\ndef create_folder_if_not_exists(folder_path):\n  # Check if the folder exists\n  if not os.path.exists(folder_path):\n      # Create the folder if it doesn't exist\n      os.makedirs(folder_path)\n      print(f\"Folder '{folder_path}' created.\")\n      print('*******************************************************')\n      print('')\n      print(f\"Folder '{folder_path}' created.\")\n      print('')\n  else:\n      print(f\"Folder '{folder_path}' already exists.\")\n      print('**************')\n      print('')\n      print(f\"Folder '{folder_path}' already exists.\")\n\n  print('*******************************************************')\n","metadata":{"id":"rFK8qXyNov9r","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:38.376675Z","iopub.execute_input":"2025-05-30T07:19:38.377301Z","iopub.status.idle":"2025-05-30T07:19:38.411795Z","shell.execute_reply.started":"2025-05-30T07:19:38.377266Z","shell.execute_reply":"2025-05-30T07:19:38.410657Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\nsMsg = 'This ML (CIC_IoT2023 ,Re-Sampling(Upsampling-SMOTE-Yeo-Johnson-transformation for multi attack, RATIOs 100%), also test Unseen 20% data with columns original order'\n# Example usage:\nprint(sMsg)\nprint('************************************************************')\nprint('')\n\nfolder_path = './best_accuracy_models_multi_attack'\ncreate_folder_if_not_exists(folder_path)\nattack_type_encoding_folder_path = './attack_type_encoding'\ncreate_folder_if_not_exists(attack_type_encoding_folder_path)","metadata":{"id":"_KKiIB6XqHhh","outputId":"a6171646-3bcb-4097-831c-7052254c1ffd","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:38.413211Z","iopub.execute_input":"2025-05-30T07:19:38.413550Z","iopub.status.idle":"2025-05-30T07:19:38.438438Z","shell.execute_reply.started":"2025-05-30T07:19:38.413525Z","shell.execute_reply":"2025-05-30T07:19:38.437533Z"}},"outputs":[{"name":"stdout","text":"This ML (CIC_IoT2023 ,Re-Sampling(Upsampling-SMOTE-Yeo-Johnson-transformation for multi attack, RATIOs 100%), also test Unseen 20% data with columns original order\n************************************************************\n\nFolder './best_accuracy_models_multi_attack' already exists.\n**************\n\nFolder './best_accuracy_models_multi_attack' already exists.\n*******************************************************\nFolder './attack_type_encoding' already exists.\n**************\n\nFolder './attack_type_encoding' already exists.\n*******************************************************\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def ResampleDataFrameForMultiLabel(df_all, classCol=\"Label\",commentOnDataframe=\"\"):\n        # Assuming 'label' is the column indicating benign (0) or attack (1)\n        # Split the data into features (X) and labels (y)\n        X = df_all.drop(classCol, axis=1)\n        y = df_all[classCol]\n\n        # Resample the imbalanced dataset using SMOTE or ADASYN\n        # Choose one of the following resampling techniques\n        # oversampler = SMOTE(sampling_strategy=0.5)  # SMOTE\n        print('')\n        print('****************************************************************')\n        print('RESAMPLE ('+commentOnDataframe+') using '+RESAMPLE_ALGORITHM+' algorithm with ratio '+str(RESAMPLING_RATIO))\n        print('****************************************************************')\n        print('')\n\n        print('y.unique() = '+str(y.unique()))\n        print('y.value_counts() = '+str(y.value_counts()))\n        print('')\n\n        if RESAMPLE_ALGORITHM == 'SMOTE':\n            oversampler = SMOTE(sampling_strategy=RESAMPLING_RATIO)  # SMOTE\n\n            # Option 1: Resample all minority classes to match the majority\n            oversampler = SMOTE(sampling_strategy='not majority')  # or 'auto' (same effect)\n\n            # Option 2: Resample all classes to the same count\n            #oversampler = SMOTE(sampling_strategy='not majority')  # good default\n\n            # Option 3: Define manually if needed\n            # oversampler = SMOTE(sampling_strategy={0: 1000, 1: 1000, 2: 1000, 3: 1000})\n        else:\n            oversampler = ADASYN(sampling_strategy=RESAMPLING_RATIO)  # ADASYN\n\n\n        X_resampled, y_resampled = oversampler.fit_resample(X, y)\n\n        # Create a DataFrame from the resampled data\n        df_all = pd.DataFrame(data=X_resampled, columns=X.columns)\n        df_all[classCol] = y_resampled\n        return df_all","metadata":{"id":"2LXKwLQQsH81","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:38.439363Z","iopub.execute_input":"2025-05-30T07:19:38.439671Z","iopub.status.idle":"2025-05-30T07:19:38.468381Z","shell.execute_reply.started":"2025-05-30T07:19:38.439641Z","shell.execute_reply":"2025-05-30T07:19:38.467428Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import os\nimport joblib\n\n# Updated train_and_evaluate_multi_attacks to support checkpointing, try-except, XGBoost incremental training, and StratifiedKFold per fold\n\ndef train_and_evaluate_multi_attacks(estimator, name, X_train, y_train, X_test, y_test, k, best_results_attack_types):\n    from xgboost import XGBClassifier\n\n    checkpoint_dir = \"/kaggle/working/ml_checkpoints\"\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    checkpoint_file = os.path.join(checkpoint_dir, f\"{name.replace(' ', '_')}_fold{k}.pkl\")\n\n    try:\n        # Skip training if checkpoint exists\n        if os.path.exists(checkpoint_file):\n            print(f\"[INFO] Skipping {name} fold {k} — checkpoint found.\")\n            estimator = joblib.load(checkpoint_file)\n            y_pred = estimator.predict(X_test)\n        else:\n            print(f\"[INFO] Training {name} fold {k} ...\")\n            if isinstance(estimator, XGBClassifier):\n                estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n            else:\n                estimator.fit(X_train, y_train)\n            joblib.dump(estimator, checkpoint_file)\n            y_pred = estimator.predict(X_test)\n\n        mcc = matthews_corrcoef(y_test, y_pred)\n        g_mean = np.sqrt(np.prod(recall_score(y_test, y_pred, average=None)))\n\n        cm = confusion_matrix(y_test, y_pred)\n        accuracy = accuracy_score(y_test, y_pred)\n        precision = precision_score(y_test, y_pred, average='macro')\n        precision_weighted = precision_score(y_test, y_pred, average='weighted')\n        recall = recall_score(y_test, y_pred, average='macro')\n        f1 = f1_score(y_test, y_pred, average='macro')\n\n        classes = np.unique(y_test)\n        y_test_bin = label_binarize(y_test, classes=classes)\n        y_pred_prob = estimator.predict_proba(X_test)\n        roc_auc = roc_auc_score(y_test_bin, y_pred_prob, average='macro', multi_class='ovr')\n\n        encoder_path = \"/kaggle/input/attacks-encoding/attack_type_label_encoder.pkl\"\n        with open(encoder_path, 'rb') as f:\n            le = pickle.load(f)\n\n        print(\"Classification Report:\")\n        print(classification_report(y_test, y_pred, target_names=le.classes_))\n\n        print(\"Confusion Matrix:\")\n        print(cm)\n\n        print(f\"Accuracy: {accuracy:.3f}\")\n        print(f\"Precision: {precision:.3f}\")\n        print(f\"Recall: {recall:.3f}\")\n        print(f\"F1 Score: {f1:.3f}\")\n        print(f\"ROC AUC: {roc_auc:.3f}\")\n\n        if accuracy > best_results_attack_types[name][\"accuracy\"]:\n            best_results_attack_types[name] = {\n                \"accuracy\": accuracy,\n                \"fold\": k,\n                \"f1\": f1,\n                \"recall\": recall,\n                \"precision_weighted\": precision_weighted,\n                \"precision\": precision,\n                \"roc_auc\": roc_auc,\n                \"confusion_mat\": cm,\n                \"MCC\": mcc,\n                \"g_mean\": g_mean,\n                \"estimator\": estimator,\n                \"X_train\": X_train,\n                \"X_test\": X_test,\n                \"y_train\": y_train,\n                \"y_test\": y_test\n            }\n\n    except Exception as e:\n        print(f\"[ERROR] Training failed for {name} fold {k}: {e}\")\n\n    return best_results_attack_types\n\n# Optional: zip checkpoint models for uploading to Kaggle Dataset manually\ndef zip_checkpoint_directory():\n    import zipfile\n    zipf = zipfile.ZipFile(\"/kaggle/working/ml_checkpoints.zip\", 'w', zipfile.ZIP_DEFLATED)\n    for root, _, files in os.walk(\"/kaggle/working/ml_checkpoints\"):\n        for file in files:\n            zipf.write(os.path.join(root, file), arcname=file)\n    zipf.close()\n    print(\"[INFO] Checkpoints zipped to /kaggle/working/ml_checkpoints.zip\")\n\n# Optional: restore previously uploaded model checkpoints from an input dataset\ndef restore_checkpoints_from_dataset():\n    input_path = \"/kaggle/input/ml-model-checkpoints\"  # Replace with actual dataset name if needed\n    target_path = \"/kaggle/working/ml_checkpoints\"\n    if os.path.exists(input_path):\n        os.makedirs(target_path, exist_ok=True)\n        for file in os.listdir(input_path):\n            if file.endswith(\".pkl\"):\n                src = os.path.join(input_path, file)\n                dst = os.path.join(target_path, file)\n                if not os.path.exists(dst):\n                    os.system(f\"cp '{src}' '{dst}'\")\n        print(\"[INFO] Restored model checkpoints from dataset.\")\n    else:\n        print(\"[INFO] No model checkpoint dataset found to restore.\")\n","metadata":{"id":"D_z6YN5FsRIZ","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:38.469550Z","iopub.execute_input":"2025-05-30T07:19:38.469892Z","iopub.status.idle":"2025-05-30T07:19:38.500022Z","shell.execute_reply.started":"2025-05-30T07:19:38.469865Z","shell.execute_reply":"2025-05-30T07:19:38.498815Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"####################### for Traditional ML training using CPU\ndef readSeqStructDataFromTable_TraditionalML_attackTypes_Training(NetSource,best_results_attack_types):\n\n    try:\n        print('***********************************************************')\n        print('********readSeqStructDataFromTable_TraditionalML_attackTypes_Training() starts *****')\n\n\n        CSVFileName = '/kaggle/input/ciciot2023multiattacks/CICIoT2023_StructProp_multi_attacks.csv'\n\n        # get all records\n        sColLst = ['MolecularWeight', 'Aromaticity', 'InstabilityIndex', 'IsoelectricPoint',\n                   'AlphaHelix', 'ReducedCysteines', 'DisulfideBridges', 'Gravy', 'BetaTurn', 'BetaStrand', 'IsBad']\n        df_ModelDataSource = pd.read_csv(CSVFileName)\n\n        # Filter only rows where NetSource == 'CIC_IoT_2023' (training set)\n        df_ModelDataSource = df_ModelDataSource[df_ModelDataSource['NetSource'] == NetSource]\n        df_ModelDataSource = df_ModelDataSource.drop(columns=['Id','Sequence', 'NetSource','Created_at'], errors='ignore')\n\n\n        print('readSeqStructDataFromTable_TraditionalML_Training: # of Records = ' + str(df_ModelDataSource.shape) +\n                     ' - for NetSource = ' + str(NetSource))\n\n        ##################### Here do Resampling #############################\n        print('***********************************************************')\n        print('********ResampleDataFrameForMultiLabel() starts *****')\n        print('***********************************************************')\n        print('')\n\n        start_time = time.time()\n        df_ModelDataSource = ResampleDataFrameForMultiLabel(df_ModelDataSource, classCol=\"IsBad\",commentOnDataframe=\"Training Data of Structural Properties for Multi attack types\")\n        end_time = time.time()\n        logExecTime(\"ResampleDataFrameForMultiLabel\", start_time, end_time)\n\n        print('')\n        print('***********************************************************')\n        print('********ResampleDataFrameForMultiLabel() ends *****')\n        print('***********************************************************')\n        print('')\n\n        ##################### END Resampling #################################\n\n        print('***********************************************************')\n        print('')\n        print('After Resample, Total Training rows count (Benign & Attack) = '+str(len(df_ModelDataSource)))\n        print('')\n        import pickle\n\n        # Load the saved label encoder\n        encoder_path = \"/kaggle/input/attacks-encoding/attack_type_label_encoder.pkl\"\n        with open(encoder_path, \"rb\") as f:\n            label_encoder = pickle.load(f)\n\n        # Decode labels and show counts with original attack names\n        df_ModelDataSource['attack_type_decoded'] = label_encoder.inverse_transform(df_ModelDataSource['IsBad'])\n        print('\\nAfter Resample - Training rows count by Attack Type:')\n        print(df_ModelDataSource['attack_type_decoded'].value_counts())\n        df_ModelDataSource = df_ModelDataSource.drop(columns=['attack_type_decoded'], errors='ignore')\n        print('***********************************************************')\n\n\n        # Separate features and labels\n        X = df_ModelDataSource.loc[:, ~df_ModelDataSource.columns.isin(['IsBad'])]\n        y = df_ModelDataSource['IsBad']\n\n        # Split data into training and testing sets\n        stratified_splitter = StratifiedShuffleSplit(n_splits=K_FOLD_SPLITS, test_size=0.2, random_state=42)\n        print(\"\")\n        print('----------------------Data preprocessing (Yeo-Johnson Transformation) starts')\n\n        # Apply Yeo-Johnson transformation\n        pt = PowerTransformer(method='yeo-johnson')\n        X_transformed = pt.fit_transform(X)\n        #X_test_transformed = pt.transform(X_test)\n\n        print('----------------------Data preprocessing (Yeo-Johnson Transformation) ends')\n        print(\"\")\n\n        print('***********************************************************')\n        print('Calculating Skewness & Kurtosis values for Training data(X_train) after applying yeo-johnson transformation')\n        print('')\n\n        log_skewness_kurtosis(X_transformed, X.columns)\n\n        # Optionally, perform feature scaling\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X_transformed)\n\n        # Initialize traditional ML classifiers\n        nMLIterations = 100 #standard=1000\n        n_MLestimators=10 #standard=50\n        num_classes = len(np.unique(y))  # use your encoded y\n\n        classifiers = {\n            'Naive Bayes': GaussianNB(),\n            'Logistic Regression': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=nMLIterations),\n            'Decision Tree': DecisionTreeClassifier(random_state=42),\n            'K-Nearest Neighbor': KNeighborsClassifier(),\n            'Support Vector Machine': SVC(probability=True, decision_function_shape='ovr'),\n            'Random Forest': RandomForestClassifier(random_state=42),\n            'XGBoost': XGBClassifier(objective='multi:softprob', num_class=num_classes, use_label_encoder=False, eval_metric='mlogloss'),\n            'AdaBoost': AdaBoostClassifier(algorithm='SAMME', random_state=42),\n            'CatBoost': CatBoostClassifier(iterations=nMLIterations, learning_rate=0.1, depth=6, verbose=0),\n            'Bagging': BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=n_MLestimators, random_state=42),\n            'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n        }\n\n        k=0\n        for train_index, test_index in stratified_splitter.split(X_scaled, y):\n            X_train_scaled, X_test_scaled = X_scaled[train_index], X_scaled[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n\n            print(\"******************************** \")\n            print(\" \")\n            k+=1\n            print(\"*********** K fold No = \"+str(k))\n            print(\" \")\n\n            # Train and evaluate each classifier\n            for name, classifier in classifiers.items():\n                print(f\"Training and evaluating classifier: {name} ...\")\n                best_results_attack_types = train_and_evaluate_multi_attacks(classifier,name, X_train_scaled, y_train, X_test_scaled, y_test,k,best_results_attack_types)\n\n                ############################# print performance\n\n            # Create stacking classifiers\n            num_classes = len(np.unique(y))  # Use the encoded label array\n\n            stacking_classifiers = [\n                ('rf', RandomForestClassifier(random_state=42)),\n                ('xgb', XGBClassifier(objective='multi:softprob', num_class=num_classes, use_label_encoder=False, eval_metric='mlogloss')),\n                ('ada', AdaBoostClassifier(algorithm='SAMME', random_state=42)),\n                ('cat', CatBoostClassifier(iterations=nMLIterations, learning_rate=0.1, depth=6, verbose=0))\n            ]\n\n            # Define meta-models\n            meta_models = {\n                'Stacking(Logistic Regression)': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=nMLIterations),\n                'Stacking(Decision Tree)': DecisionTreeClassifier(random_state=42)\n            }\n\n                # Train and evaluate stacking classifiers\n            for meta_name, meta_model in meta_models.items():\n                stacking_clf = StackingClassifier(\n                    estimators=stacking_classifiers,\n                    final_estimator=meta_model,\n                    passthrough=True,\n                    cv=K_FOLD_SPLITS,\n                    n_jobs=-1  # Optional: enables parallelism\n                )\n                print(f\"Training and evaluating stacking classifier with meta-model: {meta_name} ...\")\n\n                best_results_attack_types = train_and_evaluate_multi_attacks(stacking_clf, meta_name, X_train_scaled, y_train, X_test_scaled, y_test,k,best_results_attack_types)\n\n        print('***********************************************************')\n        print('readSeqStructDataFromTable_TraditionalML_Training ends')\n        print('***********************************************************')\n\n    except OSError as err:\n        print(\"OS Error: \" + str(err))\n\n        raise RuntimeError from err\n    except BaseException as err:\n        print(\"Unexpected exception \" + str(err))\n\n        raise RuntimeError from err\n    except:\n        print(\"Unexpected error:\", sys.exc_info()[0])\n        raise RuntimeError\n    return best_results_attack_types","metadata":{"id":"lDPiVc91t2gu","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:38.501375Z","iopub.execute_input":"2025-05-30T07:19:38.501903Z","iopub.status.idle":"2025-05-30T07:19:38.530113Z","shell.execute_reply.started":"2025-05-30T07:19:38.501878Z","shell.execute_reply":"2025-05-30T07:19:38.529079Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"NetSource='CIC_IoT_2023_multi_attack'\nbest_results_attack_types = readSeqStructDataFromTable_TraditionalML_attackTypes_Training(NetSource,best_results_attack_types)\nzip_checkpoint_directory()","metadata":{"id":"RVZtDxdDuMkF","outputId":"ecaf27ab-0b22-4f48-c324-290083683670","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:19:38.532617Z","iopub.execute_input":"2025-05-30T07:19:38.532996Z","execution_failed":"2025-05-31T06:10:11.734Z"}},"outputs":[{"name":"stdout","text":"***********************************************************\n********readSeqStructDataFromTable_TraditionalML_attackTypes_Training() starts *****\nreadSeqStructDataFromTable_TraditionalML_Training: # of Records = (163804, 11) - for NetSource = CIC_IoT_2023_multi_attack\n***********************************************************\n********ResampleDataFrameForMultiLabel() starts *****\n***********************************************************\n\n\n****************************************************************\nRESAMPLE (Training Data of Structural Properties for Multi attack types) using SMOTE algorithm with ratio 1.0\n****************************************************************\n\ny.unique() = [ 0  4  7  9  8 10  5 14  3 13  1  2  6 11 12]\ny.value_counts() = IsBad\n0     79995\n8      8000\n13     8000\n6      8000\n10     7999\n5      7994\n4      7986\n9      7985\n7      7983\n2      4687\n3      4327\n11     4195\n14     3077\n1      2574\n12     1002\nName: count, dtype: int64\n\nResampleDataFrameForMultiLabel (Execution time) : 0.03 minutes\n\n-------------------\nResampleDataFrameForMultiLabel (Execution time) : 0.03 minutes\n-------------------\n\n\n***********************************************************\n********ResampleDataFrameForMultiLabel() ends *****\n***********************************************************\n\n***********************************************************\n\nAfter Resample, Total Training rows count (Benign & Attack) = 1199925\n\n\nAfter Resample - Training rows count by Attack Type:\nattack_type_decoded\n                        79995\nDDoS                    79995\nDoS                     79995\nMirai                   79995\nMITM                    79995\nRecon                   79995\nDNS_Spoofing            79995\nXSS                     79995\nCommandInjection        79995\nVulnerabilityScan       79995\nBackdoor_Malware        79995\nBrowserHijacking        79995\nDictionaryBruteForce    79995\nSqlInjection            79995\nUploading_Attack        79995\nName: count, dtype: int64\n***********************************************************\n\n----------------------Data preprocessing (Yeo-Johnson Transformation) starts\n----------------------Data preprocessing (Yeo-Johnson Transformation) ends\n\n***********************************************************\nCalculating Skewness & Kurtosis values for Training data(X_train) after applying yeo-johnson transformation\n\n\n***********************************************************************\nlog_skewness_kurtosis starts\n\nFeature: MolecularWeight - Skewness: 0.14581700144435303, Kurtosis: -0.4254217494682315\nFeature: Aromaticity - Skewness: -0.0038523273605025827, Kurtosis: 0.12100505929371552\nFeature: InstabilityIndex - Skewness: -0.0002638471132447865, Kurtosis: -0.02686218167022325\nFeature: IsoelectricPoint - Skewness: -0.10480005224380473, Kurtosis: -0.09328932774816012\nFeature: AlphaHelix - Skewness: 0.0016673673976052154, Kurtosis: 0.10200955756976926\nFeature: ReducedCysteines - Skewness: -0.039078879376991185, Kurtosis: 0.056996710427410946\nFeature: DisulfideBridges - Skewness: -0.039078879376991185, Kurtosis: 0.056996710427410946\nFeature: Gravy - Skewness: -0.004926811524213164, Kurtosis: -0.2656796941029449\nFeature: BetaTurn - Skewness: -0.0005627243769268616, Kurtosis: -0.31579491342254595\nFeature: BetaStrand - Skewness: 0.002636808926129018, Kurtosis: -0.20007129298664283\nlog_skewness_kurtosis ends\n***********************************************************************\n******************************** \n \n*********** K fold No = 1\n \nTraining and evaluating classifier: Naive Bayes ...\n \n ---------------------------------------------- \n-----------------train_and_evaluate_multi_attacks()---------- starts\n \nThis evaluation result is from Machine Learning model train_and_evaluate_multi_attacks()\n******************************\nMatthews correlation coefficient (MCC) for Naive Bayes: 0.16975930237392503\nG-mean for Naive Bayes: 7.667276093564938e-08\n******************************\n['' 'Backdoor_Malware' 'BrowserHijacking' 'CommandInjection' 'DDoS'\n 'DNS_Spoofing' 'DictionaryBruteForce' 'DoS' 'MITM' 'Mirai' 'Recon'\n 'SqlInjection' 'Uploading_Attack' 'VulnerabilityScan' 'XSS']\nClassification Report:\n                      precision    recall  f1-score   support\n\n                           0.15      0.29      0.20     15999\n    Backdoor_Malware       0.12      0.03      0.05     15999\n    BrowserHijacking       0.15      0.06      0.09     15999\n    CommandInjection       0.14      0.06      0.09     15999\n                DDoS       0.37      0.75      0.50     15999\n        DNS_Spoofing       0.11      0.01      0.01     15999\nDictionaryBruteForce       0.12      0.08      0.10     15999\n                 DoS       0.16      0.09      0.12     15999\n                MITM       0.12      0.03      0.05     15999\n               Mirai       0.20      0.24      0.22     15999\n               Recon       0.14      0.10      0.12     15999\n        SqlInjection       0.14      0.21      0.17     15999\n    Uploading_Attack       0.14      0.39      0.20     15999\n   VulnerabilityScan       0.54      0.91      0.67     15999\n                 XSS       0.12      0.07      0.08     15999\n\n            accuracy                           0.22    239985\n           macro avg       0.18      0.22      0.18    239985\n        weighted avg       0.18      0.22      0.18    239985\n\nConfusion Matrix:\n[[ 4597   311   690   469   323   123   580   154   483   681   602  1233\n   2335  2829   589]\n [ 1974   520   410   357   447    27   955   463   438  1194  1100  2508\n   4200   515   891]\n [ 3183   347   983   556   576    50   697   365   413   904   931  1960\n   3010  1365   659]\n [ 1968   301   676  1016   851    86  1022   730   401  1100   836  1955\n   3809   634   614]\n [  155    79    59   118 12062    16    17   729    14  1299   294   154\n    726   185    92]\n [ 2807   276   639   558   870   127   937   364   425  1137   824  1606\n   3448  1374   607]\n [ 1879   447   600   825   189    66  1257   248   460  1062   915  2643\n   4119   444   845]\n [  287   253    80   282  9282     2    63  1435    17  1661   384   618\n   1078   291   266]\n [ 3808   271   581   415   649    97   669   443   510   793   891  1282\n   2573  2328   689]\n [ 1703   173   454   278  4212   446   106  1949    79  3886   270   117\n   1158   948   220]\n [ 1455   354   436   471  2387    33   774   988   223  1245  1617  1804\n   3075   577   560]\n [ 1760   401   613   694    66    36   945   223   343  1212   751  3371\n   4306   379   899]\n [ 1424   293   177   455   214    32  1093   361   177  1582  1104  1809\n   6191   233   854]\n [ 1261     4    31     9     0     1     7     1     6    29     3    27\n     29 14575    16]\n [ 1722   437   277   580   376    37  1059   358   387  1222   830  2345\n   4767   549  1053]]\n\n===== Evaluation Metrics for Naive Bayes =====\nHere are specific Evaluation Metrics values:\nAccuracy: 0.222\nPrecision: 0.182\nRecall: 0.222\nF1 Score: 0.178\nROC AUC: 0.721\n \n******************************** \n \n-----------------train_and_evaluate_multi_attacks()---------- ends\nTraining and evaluating classifier: Logistic Regression ...\n \n ---------------------------------------------- \n-----------------train_and_evaluate_multi_attacks()---------- starts\n \nThis evaluation result is from Machine Learning model train_and_evaluate_multi_attacks()\n","output_type":"stream"},{"name":"stderr","text":"'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\nlbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","output_type":"stream"},{"name":"stdout","text":"******************************\nMatthews correlation coefficient (MCC) for Logistic Regression: 0.23850987708193083\nG-mean for Logistic Regression: 3.358872590290812e-06\n******************************\n['' 'Backdoor_Malware' 'BrowserHijacking' 'CommandInjection' 'DDoS'\n 'DNS_Spoofing' 'DictionaryBruteForce' 'DoS' 'MITM' 'Mirai' 'Recon'\n 'SqlInjection' 'Uploading_Attack' 'VulnerabilityScan' 'XSS']\nClassification Report:\n                      precision    recall  f1-score   support\n\n                           0.19      0.23      0.21     15999\n    Backdoor_Malware       0.15      0.14      0.15     15999\n    BrowserHijacking       0.17      0.13      0.15     15999\n    CommandInjection       0.11      0.09      0.10     15999\n                DDoS       0.53      0.64      0.58     15999\n        DNS_Spoofing       0.13      0.05      0.07     15999\nDictionaryBruteForce       0.17      0.04      0.07     15999\n                 DoS       0.39      0.49      0.44     15999\n                MITM       0.17      0.17      0.17     15999\n               Mirai       0.41      0.65      0.50     15999\n               Recon       0.19      0.15      0.17     15999\n        SqlInjection       0.17      0.20      0.19     15999\n    Uploading_Attack       0.17      0.35      0.23     15999\n   VulnerabilityScan       0.72      0.94      0.82     15999\n                 XSS       0.13      0.04      0.06     15999\n\n            accuracy                           0.29    239985\n           macro avg       0.25      0.29      0.26    239985\n        weighted avg       0.25      0.29      0.26    239985\n\nConfusion Matrix:\n[[ 3603   738  1201   820   132   463   193   349  2027  1064   634  1271\n   1788  1466   250]\n [  941  2279   813   907   428   480   322   611  1397   906  1303  1988\n   2971    87   566]\n [ 2045  1114  2090  1155   413   588   142   545  1547   966  1058  1502\n   1938   541   355]\n [ 1477  1165  1138  1436   789   613   348  1260  1111  1061   751  1558\n   2625   304   363]\n [   94    94    57   235 10274    20     1  3091    25  1383   166    94\n    277   158    30]\n [ 1917  1073  1208  1005   608   794   269   406  1568  1512   955  1221\n   2466   687   310]\n [ 1470  1499  1012  1223   167   532   648   466  1594   915   867  2056\n   2899   123   528]\n [  205   254   158   534  3656    21    11  7866    84  1317   764   419\n    365   189   156]\n [ 2876  1042  1050   704   199   453   273   379  2728  1133  1104   901\n   1882   984   291]\n [  508    32   216   308  1156    95     0  2024   117 10404   208    15\n    261   628    27]\n [  884  1240   865   851   912   516   282  1517   988  1439  2420  1405\n   2174   221   285]\n [ 1011  1596  1194  1354    94   422   452   557   873  1011   785  3265\n   2709   112   564]\n [  642  1374   392  1134   258   560   450   458  1045  1144   880  1405\n   5539    70   648]\n [  433    15   132    47     0    15     0    20    94    88     4    84\n     62 14992    13]\n [  783  1735   664  1202   266   524   438   593  1217  1094   824  2035\n   3794   149   681]]\n\n===== Evaluation Metrics for Logistic Regression =====\nHere are specific Evaluation Metrics values:\nAccuracy: 0.288\nPrecision: 0.254\nRecall: 0.288\nF1 Score: 0.259\nROC AUC: 0.766\n \n******************************** \n \n-----------------train_and_evaluate_multi_attacks()---------- ends\nTraining and evaluating classifier: Decision Tree ...\n \n ---------------------------------------------- \n-----------------train_and_evaluate_multi_attacks()---------- starts\n \nThis evaluation result is from Machine Learning model train_and_evaluate_multi_attacks()\n******************************\nMatthews correlation coefficient (MCC) for Decision Tree: 0.6294604889409303\nG-mean for Decision Tree: 0.035258596151868854\n******************************\n['' 'Backdoor_Malware' 'BrowserHijacking' 'CommandInjection' 'DDoS'\n 'DNS_Spoofing' 'DictionaryBruteForce' 'DoS' 'MITM' 'Mirai' 'Recon'\n 'SqlInjection' 'Uploading_Attack' 'VulnerabilityScan' 'XSS']\nClassification Report:\n                      precision    recall  f1-score   support\n\n                           0.50      0.45      0.47     15999\n    Backdoor_Malware       0.70      0.73      0.72     15999\n    BrowserHijacking       0.58      0.59      0.59     15999\n    CommandInjection       0.62      0.63      0.63     15999\n                DDoS       0.80      0.80      0.80     15999\n        DNS_Spoofing       0.50      0.49      0.49     15999\nDictionaryBruteForce       0.51      0.50      0.51     15999\n                 DoS       0.75      0.74      0.75     15999\n                MITM       0.50      0.49      0.50     15999\n               Mirai       0.79      0.79      0.79     15999\n               Recon       0.56      0.54      0.55     15999\n        SqlInjection       0.63      0.64      0.63     15999\n    Uploading_Attack       0.83      0.87      0.85     15999\n   VulnerabilityScan       0.84      0.83      0.83     15999\n                 XSS       0.67      0.69      0.68     15999\n\n            accuracy                           0.65    239985\n           macro avg       0.65      0.65      0.65    239985\n        weighted avg       0.65      0.65      0.65    239985\n\nConfusion Matrix:\n[[ 7203   397   792   609   153  1068   967   301  1178   479   771   599\n    207   756   519]\n [  337 11740   408   361    87   428   500   123   407   106   429   448\n    207    23   395]\n [  570   485  9505   581   131   799   676   169   775   228   631   535\n    204   224   486]\n [  473   403   564 10092   105   665   679   182   595   193   541   569\n    281   116   541]\n [  119   100   119   111 12814   165   112  1430   115   301   318    87\n     48    51   109]\n [  886   558   809   703   186  7822   850   218  1028   362   750   617\n    318   315   577]\n [  788   630   716   767   123   849  8070   212   790   230   807   858\n    314    84   761]\n [  246   146   212   224  1419   231   216 11916   181   356   318   207\n     77    65   185]\n [  993   525   851   620   126   974   839   182  7911   336   732   561\n    274   520   555]\n [  464   109   245   218   325   389   239   300   364 12582   278   131\n     49   188   118]\n [  641   505   648   627   310   744   849   322   718   309  8712   654\n    300    81   579]\n [  533   516   511   555    96   550   773   179   485   126   583 10217\n    261    73   541]\n [  120   155   183   209    38   230   239    60   187    36   194   182\n  13982    15   169]\n [  685    45   282   148    46   314    88    77   544   215   112    63\n     29 13304    47]\n [  328   404   438   450    87   491   648   146   476   119   496   490\n    261    52 11113]]\n\n===== Evaluation Metrics for Decision Tree =====\nHere are specific Evaluation Metrics values:\nAccuracy: 0.654\nPrecision: 0.652\nRecall: 0.654\nF1 Score: 0.653\nROC AUC: 0.815\n \n******************************** \n \n-----------------train_and_evaluate_multi_attacks()---------- ends\nTraining and evaluating classifier: K-Nearest Neighbor ...\n \n ---------------------------------------------- \n-----------------train_and_evaluate_multi_attacks()---------- starts\n \nThis evaluation result is from Machine Learning model train_and_evaluate_multi_attacks()\n******************************\nMatthews correlation coefficient (MCC) for K-Nearest Neighbor: 0.7371071898567312\nG-mean for K-Nearest Neighbor: 0.07947490934902125\n******************************\n['' 'Backdoor_Malware' 'BrowserHijacking' 'CommandInjection' 'DDoS'\n 'DNS_Spoofing' 'DictionaryBruteForce' 'DoS' 'MITM' 'Mirai' 'Recon'\n 'SqlInjection' 'Uploading_Attack' 'VulnerabilityScan' 'XSS']\nClassification Report:\n                      precision    recall  f1-score   support\n\n                           0.48      0.18      0.26     15999\n    Backdoor_Malware       0.71      0.89      0.79     15999\n    BrowserHijacking       0.67      0.79      0.73     15999\n    CommandInjection       0.70      0.80      0.75     15999\n                DDoS       0.86      0.87      0.86     15999\n        DNS_Spoofing       0.67      0.65      0.66     15999\nDictionaryBruteForce       0.68      0.66      0.67     15999\n                 DoS       0.85      0.82      0.83     15999\n                MITM       0.70      0.63      0.66     15999\n               Mirai       0.86      0.88      0.87     15999\n               Recon       0.74      0.65      0.69     15999\n        SqlInjection       0.75      0.77      0.76     15999\n    Uploading_Attack       0.82      0.97      0.89     15999\n   VulnerabilityScan       0.89      0.93      0.91     15999\n                 XSS       0.77      0.81      0.79     15999\n\n            accuracy                           0.75    239985\n           macro avg       0.74      0.75      0.74    239985\n        weighted avg       0.74      0.75      0.74    239985\n\nConfusion Matrix:\n[[ 2870  1030  1493  1130   162  1382  1154   305  1516   662   835   936\n    598  1092   834]\n [   90 14232   194   182    26   152   194    44   128    35   130   191\n    177     2   222]\n [  238   494 12679   365    58   304   290    62   287    94   290   293\n    207    68   270]\n [  212   498   429 12839    51   266   290    72   220    87   215   274\n    260    31   255]\n [   51   129   106   113 13849    85    59   987    58   224   114    57\n     50    22    95]\n [  445   630   732   644   136 10478   461   108   468   208   362   429\n    359   141   398]\n [  353   737   618   717    85   572 10501   108   327   109   406   527\n    404    31   504]\n [  127   199   167   213  1032   144   176 13093    93   241   142   126\n     64    59   123]\n [  655   638   738   534    86   657   611   114 10108   180   308   418\n    313   227   412]\n [  131   102   177   189   194   239   103   180   185 14083   125    58\n     71    81    81]\n [  343   558   623   593   251   542   609   213   416   201 10414   436\n    341    45   414]\n [  168   456   409   417    44   379   484    90   270    66   336 12350\n    244    14   272]\n [   13    66    37    51     3    45    60    12    34     5    38    52\n  15547     0    36]\n [  167    38   147    91    14   165    37    24   207    90    43    28\n     21 14882    45]\n [  131   358   292   318    47   254   360    58   208    71   257   352\n    329    17 12947]]\n\n===== Evaluation Metrics for K-Nearest Neighbor =====\nHere are specific Evaluation Metrics values:\nAccuracy: 0.754\nPrecision: 0.743\nRecall: 0.754\nF1 Score: 0.741\nROC AUC: 0.945\n \n******************************** \n \n-----------------train_and_evaluate_multi_attacks()---------- ends\nTraining and evaluating classifier: Support Vector Machine ...\n \n ---------------------------------------------- \n-----------------train_and_evaluate_multi_attacks()---------- starts\n \nThis evaluation result is from Machine Learning model train_and_evaluate_multi_attacks()\n","output_type":"stream"}],"execution_count":null}]}