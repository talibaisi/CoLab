{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talibaisi/CoLab/blob/master/engine_v3_0_0_1_IoT2023_Classifier_multiAttack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l6axIDU6o400",
        "outputId": "9392815e-e22e-4bb2-b250-8092d01740e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost, scikeras\n",
            "Successfully installed catboost-1.2.8 scikeras-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D5ALZZ_PvFhw",
        "outputId": "c5705f29-72a8-4b74-e8d5-c36fe992a468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZxvdrYlkn84J"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "# ✅ Disable HuggingFace transformer model detection in SHAP\n",
        "shap.utils.transformers.is_transformers_lm = lambda x: False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gghv_9nmome1"
      },
      "outputs": [],
      "source": [
        "# Assistantxxxx\n",
        "# Assistant\n",
        "# First, install the missing package\n",
        "#!pip install tensorflow==2.10.0 keras==2.10.0 scikeras --upgrade\n",
        "#!pip install catboost\n",
        "\n",
        "# Then your imports can work correctly\n",
        "from sklearn.linear_model import SGDClassifier  # Corrected import - SGDClassifier is in linear_model, not model_selection\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import scale\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
        "import joblib\n",
        "from joblib import dump, load\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.ensemble import StackingClassifier,BaggingClassifier, GradientBoostingClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Use the updated import for KerasClassifier\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import datetime\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.ensemble import IsolationForest,StackingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier  # This will work after installation\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import torch.nn.functional as F\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "#General hyper parameters\n",
        "K_FOLD_SPLITS=5\n",
        "EPOCHS = 5 #100\n",
        "RESAMPLE_ALGORITHM = 'SMOTE' #'ADASYN' #USE 'NONE' in case no sampling\n",
        "RESAMPLING_RATIO = 1.0\n",
        "LIME_FORCE_PLOT_SAMPLE_SLICE = 100\n",
        "\n",
        "best_results = {\n",
        "'Naive Bayes': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Logistic Regression': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Decision Tree': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'K-Nearest Neighbor': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Support Vector Machine': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Random Forest': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'XGBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'AdaBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'CatBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Bagging': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Gradient Boosting': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'CNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'RNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'LSTM Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'GRU Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "#'GNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Stacking(Logistic Regression)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Stacking(Decision Tree)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None}\n",
        "}\n",
        "#################### multi label (attack_type)\n",
        "best_results_attack_types= {\n",
        "'Naive Bayes': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Logistic Regression': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Decision Tree': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'K-Nearest Neighbor': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Support Vector Machine': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Random Forest': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'XGBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'AdaBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'CatBoost': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Bagging': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Gradient Boosting': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'CNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'RNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'LSTM Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'GRU Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "#'GNN Classifier': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"fpr\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Stacking(Logistic Regression)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None},\n",
        "'Stacking(Decision Tree)': {\"accuracy\": 0, \"fold\": -1,\"f1\":-1,\"recall\":-1,\"precision_weighted\":-1,\"precision\":-1,\"roc_auc\":-1,\"confusion_mat\":None,\"MCC\":-1,\"g_mean\": -1, \"estimator\": None, \"X_train\": None, \"X_test\": None, \"y_train\": None, \"y_test\": None,\"file_path\":None}\n",
        "}\n",
        "# Rest of your code remains the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rFK8qXyNov9r"
      },
      "outputs": [],
      "source": [
        "#==================================================\n",
        "def is_stacking_tree_model(model_name, estimator):\n",
        "    if 'Stacking' in model_name and isinstance(estimator, StackingClassifier):\n",
        "        if isinstance(estimator.final_estimator_, (DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier)):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def is_stacking_non_tree_model(model_name, estimator):\n",
        "    if 'Stacking' in model_name and isinstance(estimator, StackingClassifier):\n",
        "        if isinstance(estimator.final_estimator_, (LogisticRegression, SVC, KNeighborsClassifier)):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def logExecTime(strMethodName, start_time, end_time):\n",
        "    # Calculate the execution time in seconds\n",
        "    execution_time_seconds = end_time - start_time\n",
        "\n",
        "    # Convert the execution time to minutes\n",
        "    execution_time_minutes = execution_time_seconds / 60\n",
        "\n",
        "    # Print the execution time in minutes\n",
        "    print(str(strMethodName) + \" (Execution time) : {:.2f} minutes\".format(execution_time_minutes))\n",
        "\n",
        "    print('')\n",
        "    print('-------------------')\n",
        "    print(str(strMethodName) + \" (Execution time) : {:.2f} minutes\".format(execution_time_minutes))\n",
        "    print('-------------------')\n",
        "    print('')\n",
        "def calculate_g_mean(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    g_mean = np.sqrt(sensitivity * specificity)\n",
        "    return g_mean\n",
        "\n",
        "#Function to calculate and log skewness and kurtosis\n",
        "def log_skewness_kurtosis(data, feature_names):\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"***********************************************************************\")\n",
        "    print(\"log_skewness_kurtosis starts\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "    skewness = skew(data, axis=0)\n",
        "    kurt = kurtosis(data, axis=0)\n",
        "    for i, feature in enumerate(feature_names):\n",
        "        print(f\"Feature: {feature} - Skewness: {skewness[i]}, Kurtosis: {kurt[i]}\")\n",
        "\n",
        "    print(\"log_skewness_kurtosis ends\")\n",
        "    print(\"***********************************************************************\")\n",
        "\n",
        "# Define a function to split a floating-point value and return both parts\n",
        "def split_float(value):\n",
        "    try:\n",
        "        float_value = float(value)\n",
        "        before_dot = int(float_value)\n",
        "        after_dot = float_value - before_dot\n",
        "        return before_dot, after_dot\n",
        "    except ValueError:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "#Recursive To Vigesemal\n",
        "def tovigisemal(decimalstring):\n",
        "    dec = int(decimalstring)\n",
        "    x = (dec % 20)\n",
        "    digits = \"0123456789ABCDEFGHIJ\"\n",
        "    rest = dec / 20\n",
        "    if (rest == 0):\n",
        "        return digits[x]\n",
        "    return tovigisemal(rest) + digits[x]\n",
        "\n",
        "def sendJobFinishAlertMail(sFrom=\"ta0002@gmail.com\",sTo=\"ta0002@gmail.com\",sSubject=\"Job Finished\",sMessage=\"Your job is finished!\"):\n",
        "    # Email configuration\n",
        "    sender_email = sFrom\n",
        "    receiver_email = sTo\n",
        "    password = \"ywdorcecnqwqmsiz\"\n",
        "\n",
        "    # Create a MIMEText object\n",
        "    message = MIMEText(sMessage)\n",
        "\n",
        "    # Set the email subject\n",
        "    message[\"Subject\"] = sSubject\n",
        "\n",
        "    # Connect to the SMTP server\n",
        "    smtp_server = \"smtp.gmail.com\"\n",
        "    smtp_port = 587\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, password)\n",
        "\n",
        "        # Send the email\n",
        "        server.sendmail(sender_email, receiver_email, message.as_string())\n",
        "\n",
        "        # Close the server connection\n",
        "        server.quit()\n",
        "        print(\"Email sent successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Email could not be sent. Error: {str(e)}\")\n",
        "\n",
        "    return\n",
        "\n",
        "def create_folder_if_not_exists(folder_path):\n",
        "  # Check if the folder exists\n",
        "  if not os.path.exists(folder_path):\n",
        "      # Create the folder if it doesn't exist\n",
        "      os.makedirs(folder_path)\n",
        "      print(f\"Folder '{folder_path}' created.\")\n",
        "      print('*******************************************************')\n",
        "      print('')\n",
        "      print(f\"Folder '{folder_path}' created.\")\n",
        "      print('')\n",
        "  else:\n",
        "      print(f\"Folder '{folder_path}' already exists.\")\n",
        "      print('**************')\n",
        "      print('')\n",
        "      print(f\"Folder '{folder_path}' already exists.\")\n",
        "\n",
        "  print('*******************************************************')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KKiIB6XqHhh",
        "outputId": "a6171646-3bcb-4097-831c-7052254c1ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This ML (CIC_IoT2023 ,Re-Sampling(Upsampling-SMOTE-Yeo-Johnson-transformation for multi attack, RATIOs 100%), also test Unseen 20% data with columns original order\n",
            "************************************************************\n",
            "\n",
            "Folder './best_accuracy_models_multi_attack' created.\n",
            "*******************************************************\n",
            "\n",
            "Folder './best_accuracy_models_multi_attack' created.\n",
            "\n",
            "*******************************************************\n",
            "Folder './attack_type_encoding' created.\n",
            "*******************************************************\n",
            "\n",
            "Folder './attack_type_encoding' created.\n",
            "\n",
            "*******************************************************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sMsg = 'This ML (CIC_IoT2023 ,Re-Sampling(Upsampling-SMOTE-Yeo-Johnson-transformation for multi attack, RATIOs 100%), also test Unseen 20% data with columns original order'\n",
        "# Example usage:\n",
        "print(sMsg)\n",
        "print('************************************************************')\n",
        "print('')\n",
        "\n",
        "folder_path = './best_accuracy_models_multi_attack'\n",
        "create_folder_if_not_exists(folder_path)\n",
        "attack_type_encoding_folder_path = './attack_type_encoding'\n",
        "create_folder_if_not_exists(attack_type_encoding_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2LXKwLQQsH81"
      },
      "outputs": [],
      "source": [
        "def ResampleDataFrameForMultiLabel(df_all, classCol=\"Label\",commentOnDataframe=\"\"):\n",
        "        # Assuming 'label' is the column indicating benign (0) or attack (1)\n",
        "        # Split the data into features (X) and labels (y)\n",
        "        X = df_all.drop(classCol, axis=1)\n",
        "        y = df_all[classCol]\n",
        "\n",
        "        # Resample the imbalanced dataset using SMOTE or ADASYN\n",
        "        # Choose one of the following resampling techniques\n",
        "        # oversampler = SMOTE(sampling_strategy=0.5)  # SMOTE\n",
        "        print('')\n",
        "        print('****************************************************************')\n",
        "        print('RESAMPLE ('+commentOnDataframe+') using '+RESAMPLE_ALGORITHM+' algorithm with ratio '+str(RESAMPLING_RATIO))\n",
        "        print('****************************************************************')\n",
        "        print('')\n",
        "\n",
        "        print('y.unique() = '+str(y.unique()))\n",
        "        print('y.value_counts() = '+str(y.value_counts()))\n",
        "        print('')\n",
        "\n",
        "        if RESAMPLE_ALGORITHM == 'SMOTE':\n",
        "            oversampler = SMOTE(sampling_strategy=RESAMPLING_RATIO)  # SMOTE\n",
        "\n",
        "            # Option 1: Resample all minority classes to match the majority\n",
        "            oversampler = SMOTE(sampling_strategy='not majority')  # or 'auto' (same effect)\n",
        "\n",
        "            # Option 2: Resample all classes to the same count\n",
        "            #oversampler = SMOTE(sampling_strategy='not majority')  # good default\n",
        "\n",
        "            # Option 3: Define manually if needed\n",
        "            # oversampler = SMOTE(sampling_strategy={0: 1000, 1: 1000, 2: 1000, 3: 1000})\n",
        "        else:\n",
        "            oversampler = ADASYN(sampling_strategy=RESAMPLING_RATIO)  # ADASYN\n",
        "\n",
        "\n",
        "        X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "        # Create a DataFrame from the resampled data\n",
        "        df_all = pd.DataFrame(data=X_resampled, columns=X.columns)\n",
        "        df_all[classCol] = y_resampled\n",
        "        return df_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D_z6YN5FsRIZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "import pickle\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "def train_and_evaluate_multi_attacks(estimator, name, X_train, y_train, X_test, y_test,k,best_results_attack_types):\n",
        "    print(\" \")\n",
        "    print(\" ---------------------------------------------- \")\n",
        "    print(\"-----------------train_and_evaluate_multi_attacks()---------- starts\")\n",
        "    print(\" \")\n",
        "    print(\"This evaluation result is from Machine Learning model train_and_evaluate_multi_attacks()\")\n",
        "\n",
        "    # Set options for NumPy printing\n",
        "    np.set_printoptions(precision=5, suppress=True)\n",
        "\n",
        "    # Fit the estimator and predict\n",
        "    estimator.fit(X_train, y_train)\n",
        "    y_pred = estimator.predict(X_test)\n",
        "\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    g_mean = np.sqrt(np.prod(recall_score(y_test, y_pred, average=None)))\n",
        "    #g_mean = calculate_g_mean(y_test, y_pred)\n",
        "\n",
        "    print(\"******************************\")\n",
        "    print(f\"Matthews correlation coefficient (MCC) for {name}: {mcc}\")\n",
        "    print(f\"G-mean for {name}: {g_mean}\")\n",
        "    print(\"******************************\")\n",
        "\n",
        "\n",
        "    # Generate the confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    precision_weighted = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "    # Example:\n",
        "    classes = np.unique(y_test)\n",
        "    y_test_bin = label_binarize(y_test, classes=classes)\n",
        "    y_pred_prob = estimator.predict_proba(X_test)\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test_bin, y_pred_prob, average='macro', multi_class='ovr')\n",
        "\n",
        "    #fpr = fp / (fp + tn)\n",
        "\n",
        "    # Log classification report\n",
        "    # Print classification report\n",
        "    encoder_path = \"/content/drive/MyDrive/Colab Notebooks/CICIoT2023/attack_type_encoding/attack_type_label_encoder.pkl\"\n",
        "\n",
        "    with open(encoder_path, 'rb') as f:\n",
        "        le = pickle.load(f)\n",
        "\n",
        "    print(le.classes_)  # e.g., ['Benign', 'DDoS', 'DoS', ...]\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "    #print('Classification Report:')\n",
        "    #print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    print('Confusion Matrix:')\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\n===== Evaluation Metrics for {} =====\".format(name))\n",
        "    print(\"Here are specific Evaluation Metrics values:\")\n",
        "    print(f\"Accuracy: {accuracy:.3f}\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall: {recall:.3f}\")\n",
        "    print(f\"F1 Score: {f1:.3f}\")\n",
        "    print(f\"ROC AUC: {roc_auc:.3f}\")\n",
        "    #print(f\"False Positive Rate (FPR): {fpr:.3f}\")\n",
        "\n",
        "    if accuracy > best_results_attack_types[name][\"accuracy\"]:\n",
        "        best_results_attack_types[name] = {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"fold\": k,\n",
        "            \"f1\":f1,\n",
        "            \"recall\":recall,\n",
        "            \"precision_weighted\":precision_weighted,\n",
        "            \"precision\":precision,\n",
        "            \"roc_auc\":roc_auc,\n",
        "            \"confusion_mat\":cm, # cm.ravel()=tn, fp, fn, tp\n",
        "            \"MCC\":mcc,\n",
        "            \"g_mean\": g_mean,\n",
        "            \"estimator\": estimator,\n",
        "            \"X_train\": X_train,\n",
        "            \"X_test\": X_test,\n",
        "            \"y_train\": y_train,\n",
        "            \"y_test\": y_test\n",
        "        }\n",
        "\n",
        "\n",
        "    print(\" \")\n",
        "    print(\"******************************** \")\n",
        "    print(\" \")\n",
        "    print(\"-----------------train_and_evaluate_multi_attacks()---------- ends\")\n",
        "    return best_results_attack_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lDPiVc91t2gu"
      },
      "outputs": [],
      "source": [
        "####################### for Traditional ML training using CPU\n",
        "def readSeqStructDataFromTable_TraditionalML_attackTypes_Training(NetSource,best_results_attack_types):\n",
        "\n",
        "    try:\n",
        "        print('***********************************************************')\n",
        "        print('********readSeqStructDataFromTable_TraditionalML_attackTypes_Training() starts *****')\n",
        "\n",
        "\n",
        "        CSVFileName = '/content/drive/MyDrive/Colab Notebooks/CICIoT2023/CICIoT2023_StructProp_multi_attacks.csv'\n",
        "\n",
        "        # get all records\n",
        "        sColLst = ['MolecularWeight', 'Aromaticity', 'InstabilityIndex', 'IsoelectricPoint',\n",
        "                   'AlphaHelix', 'ReducedCysteines', 'DisulfideBridges', 'Gravy', 'BetaTurn', 'BetaStrand', 'IsBad']\n",
        "        df_ModelDataSource = pd.read_csv(CSVFileName)\n",
        "\n",
        "        # Filter only rows where NetSource == 'CIC_IoT_2023' (training set)\n",
        "        df_ModelDataSource = df_ModelDataSource[df_ModelDataSource['NetSource'] == NetSource]\n",
        "        df_ModelDataSource = df_ModelDataSource.drop(columns=['Id','Sequence', 'NetSource','Created_at'], errors='ignore')\n",
        "\n",
        "\n",
        "        print('readSeqStructDataFromTable_TraditionalML_Training: # of Records = ' + str(df_ModelDataSource.shape) +\n",
        "                     ' - for NetSource = ' + str(NetSource))\n",
        "\n",
        "        ##################### Here do Resampling #############################\n",
        "        print('***********************************************************')\n",
        "        print('********ResampleDataFrameForMultiLabel() starts *****')\n",
        "        print('***********************************************************')\n",
        "        print('')\n",
        "\n",
        "        start_time = time.time()\n",
        "        df_ModelDataSource = ResampleDataFrameForMultiLabel(df_ModelDataSource, classCol=\"IsBad\",commentOnDataframe=\"Training Data of Structural Properties for Multi attack types\")\n",
        "        end_time = time.time()\n",
        "        logExecTime(\"ResampleDataFrameForMultiLabel\", start_time, end_time)\n",
        "\n",
        "        print('')\n",
        "        print('***********************************************************')\n",
        "        print('********ResampleDataFrameForMultiLabel() ends *****')\n",
        "        print('***********************************************************')\n",
        "        print('')\n",
        "\n",
        "        ##################### END Resampling #################################\n",
        "\n",
        "        print('***********************************************************')\n",
        "        print('')\n",
        "        print('After Resample, Total Training rows count (Benign & Attack) = '+str(len(df_ModelDataSource)))\n",
        "        print('')\n",
        "        import pickle\n",
        "\n",
        "        # Load the saved label encoder\n",
        "        encoder_path = \"/content/drive/MyDrive/Colab Notebooks/CICIoT2023/attack_type_encoding/attack_type_label_encoder.pkl\"\n",
        "        with open(encoder_path, \"rb\") as f:\n",
        "            label_encoder = pickle.load(f)\n",
        "\n",
        "        # Decode labels and show counts with original attack names\n",
        "        df_ModelDataSource['attack_type_decoded'] = label_encoder.inverse_transform(df_ModelDataSource['IsBad'])\n",
        "        print('\\nAfter Resample - Training rows count by Attack Type:')\n",
        "        print(df_ModelDataSource['attack_type_decoded'].value_counts())\n",
        "        df_ModelDataSource = df_ModelDataSource.drop(columns=['attack_type_decoded'], errors='ignore')\n",
        "        print('***********************************************************')\n",
        "\n",
        "\n",
        "        # Separate features and labels\n",
        "        X = df_ModelDataSource.loc[:, ~df_ModelDataSource.columns.isin(['IsBad'])]\n",
        "        y = df_ModelDataSource['IsBad']\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        stratified_splitter = StratifiedShuffleSplit(n_splits=K_FOLD_SPLITS, test_size=0.2, random_state=42)\n",
        "        print(\"\")\n",
        "        print('----------------------Data preprocessing (Yeo-Johnson Transformation) starts')\n",
        "\n",
        "        # Apply Yeo-Johnson transformation\n",
        "        pt = PowerTransformer(method='yeo-johnson')\n",
        "        X_transformed = pt.fit_transform(X)\n",
        "        #X_test_transformed = pt.transform(X_test)\n",
        "\n",
        "        print('----------------------Data preprocessing (Yeo-Johnson Transformation) ends')\n",
        "        print(\"\")\n",
        "\n",
        "        print('***********************************************************')\n",
        "        print('Calculating Skewness & Kurtosis values for Training data(X_train) after applying yeo-johnson transformation')\n",
        "        print('')\n",
        "\n",
        "        log_skewness_kurtosis(X_transformed, X.columns)\n",
        "\n",
        "        # Optionally, perform feature scaling\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X_transformed)\n",
        "\n",
        "        # Initialize traditional ML classifiers\n",
        "        nMLIterations = 100 #standard=1000\n",
        "        n_MLestimators=10 #standard=50\n",
        "        num_classes = len(np.unique(y))  # use your encoded y\n",
        "\n",
        "        classifiers = {\n",
        "            'Naive Bayes': GaussianNB(),\n",
        "            'Logistic Regression': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=nMLIterations),\n",
        "            'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "            'K-Nearest Neighbor': KNeighborsClassifier(),\n",
        "            'Support Vector Machine': SVC(probability=True, decision_function_shape='ovr'),\n",
        "            'Random Forest': RandomForestClassifier(random_state=42),\n",
        "            'XGBoost': XGBClassifier(objective='multi:softprob', num_class=num_classes, use_label_encoder=False, eval_metric='mlogloss'),\n",
        "            'AdaBoost': AdaBoostClassifier(algorithm='SAMME', random_state=42),\n",
        "            'CatBoost': CatBoostClassifier(iterations=nMLIterations, learning_rate=0.1, depth=6, verbose=0),\n",
        "            'Bagging': BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=n_MLestimators, random_state=42),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
        "        }\n",
        "\n",
        "        k=0\n",
        "        for train_index, test_index in stratified_splitter.split(X_scaled, y):\n",
        "            X_train_scaled, X_test_scaled = X_scaled[train_index], X_scaled[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            print(\"******************************** \")\n",
        "            print(\" \")\n",
        "            k+=1\n",
        "            print(\"*********** K fold No = \"+str(k))\n",
        "            print(\" \")\n",
        "\n",
        "            # Train and evaluate each classifier\n",
        "            for name, classifier in classifiers.items():\n",
        "                print(f\"Training and evaluating classifier: {name} ...\")\n",
        "                best_results_attack_types = train_and_evaluate_multi_attacks(classifier,name, X_train_scaled, y_train, X_test_scaled, y_test,k,best_results_attack_types)\n",
        "\n",
        "                ############################# print performance\n",
        "\n",
        "            # Create stacking classifiers\n",
        "            num_classes = len(np.unique(y))  # Use the encoded label array\n",
        "\n",
        "            stacking_classifiers = [\n",
        "                ('rf', RandomForestClassifier(random_state=42)),\n",
        "                ('xgb', XGBClassifier(objective='multi:softprob', num_class=num_classes, use_label_encoder=False, eval_metric='mlogloss')),\n",
        "                ('ada', AdaBoostClassifier(algorithm='SAMME', random_state=42)),\n",
        "                ('cat', CatBoostClassifier(iterations=nMLIterations, learning_rate=0.1, depth=6, verbose=0))\n",
        "            ]\n",
        "\n",
        "            # Define meta-models\n",
        "            meta_models = {\n",
        "                'Stacking(Logistic Regression)': LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=nMLIterations),\n",
        "                'Stacking(Decision Tree)': DecisionTreeClassifier(random_state=42)\n",
        "            }\n",
        "\n",
        "                # Train and evaluate stacking classifiers\n",
        "            for meta_name, meta_model in meta_models.items():\n",
        "                stacking_clf = StackingClassifier(\n",
        "                    estimators=stacking_classifiers,\n",
        "                    final_estimator=meta_model,\n",
        "                    passthrough=True,\n",
        "                    cv=K_FOLD_SPLITS,\n",
        "                    n_jobs=-1  # Optional: enables parallelism\n",
        "                )\n",
        "                print(f\"Training and evaluating stacking classifier with meta-model: {meta_name} ...\")\n",
        "\n",
        "                best_results_attack_types = train_and_evaluate_multi_attacks(stacking_clf, meta_name, X_train_scaled, y_train, X_test_scaled, y_test,k,best_results_attack_types)\n",
        "\n",
        "        print('***********************************************************')\n",
        "        print('readSeqStructDataFromTable_TraditionalML_Training ends')\n",
        "        print('***********************************************************')\n",
        "\n",
        "    except OSError as err:\n",
        "        print(\"OS Error: \" + str(err))\n",
        "\n",
        "        raise RuntimeError from err\n",
        "    except BaseException as err:\n",
        "        print(\"Unexpected exception \" + str(err))\n",
        "\n",
        "        raise RuntimeError from err\n",
        "    except:\n",
        "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "        raise RuntimeError\n",
        "    return best_results_attack_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "RVZtDxdDuMkF",
        "outputId": "ecaf27ab-0b22-4f48-c324-290083683670"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'readSeqStructDataFromTable_TraditionalML_attackTypes_Training' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6c83cfb4b7bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNetSource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CIC_IoT_2023_multi_attack'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_results_attack_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadSeqStructDataFromTable_TraditionalML_attackTypes_Training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetSource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_results_attack_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'readSeqStructDataFromTable_TraditionalML_attackTypes_Training' is not defined"
          ]
        }
      ],
      "source": [
        "NetSource='CIC_IoT_2023_multi_attack'\n",
        "best_results_attack_types = readSeqStructDataFromTable_TraditionalML_attackTypes_Training(NetSource,best_results_attack_types)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "13L0eOas5ULFXawFmQ329psG5RR2BGpyD",
      "authorship_tag": "ABX9TyM1Lgo/0gU/RnQaeCvp6pau",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}